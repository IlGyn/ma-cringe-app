import streamlit as st
import numpy as np
import json
import io
import csv
import docx
import uuid
import torch
import requests
import socket
import aiohttp
import asyncio
import logging
import threading
from queue import Queue
from datetime import datetime
from PyPDF2 import PdfReader
from pptx import Presentation

# –î–æ–±–∞–≤–ª—è–µ–º fallback –¥–ª—è PDF –∏ –¥—Ä—É–≥–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    import pdfplumber
    PDF_PLUMBER_AVAILABLE = True
except ImportError:
    PDF_PLUMBER_AVAILABLE = False

try:
    from pptx import Presentation
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False

try:
    import openpyxl
    XLSX_AVAILABLE = True
except ImportError:
    XLSX_AVAILABLE = False

from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels
from typing import List, Dict, Any, AsyncGenerator, Tuple, Union
from collections import OrderedDict
from urllib.parse import urlparse
from embedding_cache import EmbeddingCache
import os
import html

# ==================== CONFIGURATION ====================
class Config:
    QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
    QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6334))
    COLLECTION_NAME = "chat_memory"
    OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
    MAX_FILE_SIZE_MB = 10
    MAX_CACHE_SIZE = 100
    DEFAULT_EMBEDDING_MODEL = "all-MiniLM-L6-v2"
    DEFAULT_LLM_MODEL = "Phi4-mini"
    DEBUG_MODE = os.getenv("DEBUG", "false").lower() == "true"
    EMBEDDING_CACHE_SIZE = int(os.getenv("EMBEDDING_CACHE_SIZE", 500))
    ASYNC_EMBEDDING_ENABLED = os.getenv("ASYNC_EMBEDDING_ENABLED", "true").lower() == "true"
    
    # –ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    MAX_MESSAGE_LENGTH = 5000
    CHUNK_SIZE = 800
    CHUNK_OVERLAP = 100
    MAX_CONCURRENT_UPLOADS = 3
    STREAM_TIMEOUT = 120  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞

# ==================== LOGGING ====================
logging.basicConfig(
    filename="chat_app.log",
    level=logging.INFO if not Config.DEBUG_MODE else logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

# ==================== CORE CLASSES ====================
class MessageManager:
    @staticmethod
    def load_messages(qdrant_manager, limit: int = 50) -> List[Dict[str, Any]]:
        try:
            hits = qdrant_manager.client.scroll(
                collection_name=qdrant_manager.collection_name, 
                limit=limit, 
                with_payload=True, 
                with_vectors=False
            )
            return [h.payload for h in hits[0] if h.payload is not None] if hits and hits[0] else []
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
            return []
    
    @staticmethod
    def truncate_context_by_tokens(context: List[Dict], max_tokens: int = 2000) -> List[Dict]:
        """–û–±—Ä–µ–∑–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–∫–µ–Ω–æ–≤"""
        total_chars = 0
        truncated = []
        
        for msg in reversed(context):
            content = msg.get('content', '')
            chars = len(content)
            if total_chars + chars > max_tokens * 4:
                break
            truncated.append(msg)
            total_chars += chars
        
        return list(reversed(truncated))

    @staticmethod
    def is_suspicious(content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã"""
        suspicious_phrases = [
            '—Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º',
            '—É–∂–µ –æ–±—â–∞–µ–º—Å—è —á–∞—Å—Ç–æ', 
            '–∑–Ω–∞–∫–æ–º—ã —Å –º–æ–∏–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏',
            '–Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å —Ü–µ–Ω–Ω—ã–º',
            '—Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—é',
            '—è —Ç–æ–ª—å–∫–æ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω',
            '–Ω–µ –∏–º–µ—é –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π'
        ]
        content_lower = content.lower()
        return any(pattern in content_lower for pattern in suspicious_phrases)

class QdrantManager:
    def __init__(self, host: str, port: int, collection_name: str):
        self.client = QdrantClient(host=host, port=port, prefer_grpc=True)
        self.collection_name = collection_name

    def recreate_collection(self, vector_size: int):
        try:
            self.client.delete_collection(self.collection_name)
            logging.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} —É–¥–∞–ª–µ–Ω–∞")
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é: {e}")
        
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=qmodels.VectorParams(size=vector_size, distance=qmodels.Distance.COSINE)
        )
        logging.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} —Å–æ–∑–¥–∞–Ω–∞")

    def init_collection(self, encoder):
        vector_size = encoder.get_sentence_embedding_dimension()
        try:
            collections = [c.name for c in self.client.get_collections().collections]
            if self.collection_name not in collections:
                self.recreate_collection(vector_size)
                return

            coll_info = self.client.get_collection(self.collection_name)
            coll_vectors = getattr(coll_info.config.params, 'vectors', None)

            recreate_needed = False
            if isinstance(coll_vectors, qmodels.VectorParams):
                if coll_vectors.size != vector_size:
                    recreate_needed = True
            elif isinstance(coll_vectors, dict):
                first_vec = next(iter(coll_vectors.values()), None)
                if first_vec and getattr(first_vec, 'size', None) != vector_size:
                    recreate_needed = True
            else:
                recreate_needed = True

            if recreate_needed:
                self.recreate_collection(vector_size)

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            self.recreate_collection(vector_size)

    def save_message(self, role: str, content: str, timestamp: str, encoder_manager):
        # –§–ò–õ–¨–¢–†: –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        if MessageManager.is_suspicious(content):
            logging.warning(f"–ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {content[:100]}...")
            return
        
        try:
            vector = encoder_manager.get_embedding(content)
            point = qmodels.PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload={"role": role, "content": content, "time": timestamp}
            )
            self.client.upsert(collection_name=self.collection_name, points=[point])
            logging.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {role}, {timestamp}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Qdrant: {e}")

    def search_context(self, prompt: str, encoder_manager, limit: int = 6) -> List[Dict[str, Any]]:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_key = f"{prompt}_{limit}"
        if "context_cache" not in st.session_state:
            st.session_state.context_cache = OrderedDict()
        
        cached = st.session_state.context_cache.get(cache_key)
        if cached is not None:
            logging.info(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è '{prompt}' –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫—ç—à–∞")
            return cached
        
        try:
            vector = encoder_manager.get_embedding(prompt)
  
            response = self.client.query_points(
                collection_name=self.collection_name, 
                query=vector, 
                limit=limit * 2,
                with_payload=True
            )
            
            all_results = [p.payload for p in getattr(response, 'points', [])] if getattr(response, 'points', None) is not None else []
            
            chat_messages = [msg for msg in all_results if msg.get('role') in ['user', 'assistant']]
            file_chunks = [msg for msg in all_results if msg.get('role') == 'file']
            
            recent_chat = chat_messages[-3:] if len(chat_messages) > 3 else chat_messages
            relevant_files = file_chunks[:3]
            
            result = recent_chat + relevant_files
            
            # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: —É–±–∏—Ä–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            filtered_result = [msg for msg in result if not MessageManager.is_suspicious(msg.get('content', ''))]
            
            if len(filtered_result) != len(result):
                logging.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(result) - len(filtered_result)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–æ–∏—Å–∫–∞")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            st.session_state.context_cache[cache_key] = filtered_result
            if len(st.session_state.context_cache) > Config.MAX_CACHE_SIZE:
                st.session_state.context_cache.popitem(last=False)
            
            return filtered_result
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Qdrant: {e}")
            return []

    def load_messages(self, limit: int = 50) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            hits = self.client.scroll(
                collection_name=self.collection_name, 
                limit=limit, 
                with_payload=True, 
                with_vectors=False
            )
            return [h.payload for h in hits[0] if h.payload is not None] if hits and hits[0] else []
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
            return []

    def clear_collection(self, encoder):
        try:
            self.client.delete_collection(self.collection_name)
            self.recreate_collection(encoder.get_sentence_embedding_dimension())
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")

@st.cache_resource(show_spinner=False)
def load_sentence_transformer(model_name: str = "all-MiniLM-L6-v2"):
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logging.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model_name} –Ω–∞ {device}")
    return SentenceTransformer(model_name, device=device)

class EncoderManager:
    def __init__(self):
        self.cache = EmbeddingCache(max_size=Config.EMBEDDING_CACHE_SIZE)
        self._encoder = None

    def load_encoder(self, model_name: str = "all-MiniLM-L6-v2"):
        return load_sentence_transformer(model_name)

    def get_encoder(self):
        if self._encoder is None:
            self._encoder = self.load_encoder(Config.DEFAULT_EMBEDDING_MODEL)
        return self._encoder

    def get_embedding(self, text: str, encoder=None) -> List[float]:
        if encoder is None:
            encoder = self.get_encoder()
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cached = self.cache.get(text)
        if cached is not None:
            logging.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞: {text[:50]}...")
            return cached
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        vec = encoder.encode(text, convert_to_numpy=False)
        vec_list: List[float] = []
        
        if hasattr(vec, 'tolist'):
            vec_list = [float(x) for x in vec.tolist()]
        elif isinstance(vec, (list, np.ndarray)):
            vec_list = [float(x) for x in vec]
        else:
            vec_list = [float(vec)]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self.cache.put(text, vec_list)
        return vec_list

    async def async_encode(self, texts: List[str], encoder=None, batch_size: int = 32) -> List[List[float]]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        if encoder is None:
            encoder = self.get_encoder()
            
        loop = asyncio.get_event_loop()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        cached_vectors: List[tuple] = []
        texts_to_encode: List[str] = []
        text_indices: List[int] = []
        
        for i, text in enumerate(texts):
            cached = self.cache.get(text)
            if cached is not None:
                cached_vectors.append((i, cached))
                logging.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞: {text[:50]}...")
            else:
                texts_to_encode.append(text)
                text_indices.append(i)
        
        result_vectors: List[Union[List[float], None]] = [None] * len(texts)
        
        if texts_to_encode:
            vectors = await loop.run_in_executor(
                None, 
                lambda: encoder.encode(texts_to_encode, batch_size=batch_size, convert_to_numpy=False)
            )
            
            if hasattr(vectors, 'tolist'):
                vectors = vectors.tolist()
            elif not isinstance(vectors, list):
                vectors = list(vectors)
            
            processed_vectors: List[List[float]] = []
            for vec in vectors:
                if hasattr(vec, 'tolist'):
                    vec = vec.tolist()
                if isinstance(vec, (list, np.ndarray)):
                    processed_vectors.append([float(x) for x in vec])
                else:
                    processed_vectors.append([float(vec)])
            
            for idx, vec in cached_vectors:
                result_vectors[idx] = vec
            
            for i, vec in enumerate(processed_vectors):
                text_idx = text_indices[i]
                result_vectors[text_idx] = vec
                self.cache.put(texts_to_encode[i], vec)
        else:
            for idx, vec in cached_vectors:
                result_vectors[idx] = vec
        
        final_result: List[List[float]] = []
        for vec in result_vectors:
            if vec is not None:
                final_result.append(vec)
        
        return final_result

class OllamaClient:
    def check_connection(self, host: str = "127.0.0.1", port: int = 11434, timeout: int = 2) -> bool:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(timeout)
                return sock.connect_ex((host, port)) == 0
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Ä—Ç–∞: {e}")
            return False

    def check_api(self, base_url: str) -> Tuple[bool, str]:
        if not self.check_connection():
            return False, "–ü–æ—Ä—Ç 11434 –∑–∞–∫—Ä—ã—Ç"
        try:
            r = requests.get(f"{base_url}/api/version", timeout=2)
            if r.status_code == 200:
                return True, "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
            else:
                return False, "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞"
        except requests.exceptions.RequestException as e:
            return False, str(e)

    async def ask_llm_async_stream(self, prompt: str, context: list, model: str, 
                                    base_url: str, max_tokens: int = 200,
                                    temperature: float = 0.3, top_p: float = 0.8, 
                                    top_k: int = 40) -> AsyncGenerator[str, None]:

        system_instruction = (
            "–¢—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ –∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞.\n"
            "–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π –µ—ë (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–°–æ–≥–ª–∞—Å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É...').\n"
            "–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –æ—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ –∑–Ω–∞–Ω–∏—è.\n"
            "–ù–ï –¥–æ–±–∞–≤–ª—è–π —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ '–°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º' –∏–ª–∏ '–ö–∞–∫ –¥–µ–ª–∞ —É –≤–∞—Å?'.\n"
            "–û—Ç–≤–µ—á–∞–π –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
        )
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        filtered_context = [msg for msg in context if not MessageManager.is_suspicious(msg.get('content', ''))]
        
        if len(filtered_context) != len(context):
            logging.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(context) - len(filtered_context)} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è prompt")
            context = filtered_context
        
        full_prompt = "\n".join([
            f"{m['role'].capitalize()}: {m['content']}" 
            for m in context 
            if m.get('content') and m.get('content').strip()
        ] + [f"User: {prompt}", "Assistant:"])
        
        data = {
            "model": model,
            "prompt": f"System: {system_instruction}\n{full_prompt}",
            "stream": True,
            "options": {
                "num_predict": max_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "top_k": top_k,
                "num_ctx": 8192
            }
        }
        
        async with aiohttp.ClientSession() as session:
            try:
                timeout = aiohttp.ClientTimeout(total=Config.STREAM_TIMEOUT, connect=30)
                async with session.post(f"{base_url}/api/generate", json=data, timeout=timeout) as r:
                    if r.status != 200:
                        error_text = await r.text()
                        yield f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Ollama ({r.status}): {error_text}"
                        return
                        
                    async for raw_line in r.content:
                        if not raw_line:
                            continue
                        line = raw_line.strip()
                        if not line:
                            continue
                        
                        try:
                            line_str = line.decode('utf-8')
                            if line_str.startswith('data:'):
                                json_str = line_str[5:].strip()
                            else:
                                json_str = line_str
                                
                            if json_str:
                                chunk = json.loads(json_str)
                                if 'error' in chunk:
                                    yield f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {chunk['error']}"
                                    break
                                elif chunk.get("response"):
                                    yield chunk["response"]
                                elif chunk.get("done"):
                                    break
                        except json.JSONDecodeError as je:
                            logging.warning(f"–ù–µ JSON –¥–∞–Ω–Ω—ã–µ: {line_str[:100]}...")
                            continue
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ chunk: {e}")
                            yield f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}"
                            break
            except asyncio.TimeoutError:
                yield "‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏"
            except Exception as e:
                error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Ollama: {str(e)}"
                logging.error(f"–û—à–∏–±–∫–∞ Ollama: {e}")
                yield error_msg

class FileProcessor:
    def __init__(self):
        pass

    def chunk_text(self, text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
        if not text:
            return []
        chunks = []
        start = 0
        text_len = len(text)
        while start < text_len:
            end = min(start + chunk_size, text_len)
            chunks.append(text[start:end])
            start += chunk_size - overlap
            if start >= text_len:
                break
        return chunks

    def process_file(self, file, qdrant_manager: QdrantManager, encoder_manager, max_size_mb: int = 10) -> str:
        file_ext = file.name.lower().split('.')[-1] if '.' in file.name else ""
        allowed_extensions = {"txt", "pdf", "docx", "csv"}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –Ω–æ–≤—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if PPTX_AVAILABLE:
            allowed_extensions.add("pptx")
        if XLSX_AVAILABLE:
            allowed_extensions.add("xlsx")
        
        if not file_ext:
            return f"‚ö†Ô∏è –§–∞–π–ª –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"
        
        if file_ext not in allowed_extensions:
            available_formats = ", ".join(sorted(allowed_extensions))
            return f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç .{file_ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available_formats}"
        
        if file.size > max_size_mb * 1024 * 1024:
            return f"‚ö†Ô∏è –§–∞–π–ª '{file.name}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. {max_size_mb} –ú–ë)"

        try:
            file.seek(0)
            raw_bytes = file.read()
            file.seek(0)
        except Exception as e:
            return f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file.name}: {e}"

        content = ""
        try:
            if file_ext == "txt":
                content = raw_bytes.decode("utf-8", errors="ignore")
            elif file_ext == "pdf":
                content = self._extract_pdf_content(raw_bytes)
            elif file_ext == "docx":
                content = self._extract_docx_content(raw_bytes)
            elif file_ext == "csv":
                content = self._extract_csv_content(raw_bytes)
            elif file_ext == "pptx":
                if PPTX_AVAILABLE:
                    content = self._extract_pptx_content(raw_bytes)
                else:
                    content = "‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ PPTX –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-pptx)"
            elif file_ext == "xlsx":
                if XLSX_AVAILABLE:
                    content = self._extract_xlsx_content(raw_bytes)
                else:
                    content = "‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ XLSX –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ openpyxl)"
            else:
                content = f"‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ .{file_ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"
        except Exception as e:
            content = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}"
            logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file.name}: {e}")

        chunks = self.chunk_text(content)
        if chunks:
            self._save_chunks_as_messages(chunks, datetime.now().strftime("%H:%M:%S"), qdrant_manager, encoder_manager)
            if "stats" in st.session_state:
                st.session_state.stats["files_processed"] = st.session_state.stats.get("files_processed", 0) + 1
                st.session_state.stats["chunks_saved"] = st.session_state.stats.get("chunks_saved", 0) + len(chunks)
            return f"‚úÖ –§–∞–π–ª '{file.name}' –∑–∞–≥—Ä—É–∂–µ–Ω ({len(chunks)} —á–∞–Ω–∫–æ–≤)"
        else:
            return f"‚ö†Ô∏è –§–∞–π–ª '{file.name}' –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π"

    def _extract_pdf_content(self, raw_bytes) -> str:
        # –ü—Ä–æ–±—É–µ–º PyPDF2
        try:
            reader = PdfReader(io.BytesIO(raw_bytes))
            total_pages = len(reader.pages)

            if total_pages == 0:
                return ""
            
            progress_bar = st.progress(0) if total_pages > 2 else None
            
            content_parts = []
            for i, page in enumerate(reader.pages):
                text = page.extract_text()
                if text:
                    content_parts.append(text + "\n")
                else:
                    # Fallback: –ø—Ä–æ–±—É–µ–º pdfplumber –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—É—Å—Ç–∞—è
                    if PDF_PLUMBER_AVAILABLE:
                        try:
                            with pdfplumber.open(io.BytesIO(raw_bytes)) as pdf:
                                if i < len(pdf.pages):
                                    page_obj = pdf.pages[i]
                                    text_alt = page_obj.extract_text()
                                    if text_alt:
                                        content_parts.append(text_alt + "\n")
                        except Exception:
                            pass
                
                if progress_bar and i % max(1, total_pages // 20) == 0:
                    progress_bar.progress((i + 1) / total_pages)
            
            if progress_bar:
                progress_bar.empty()
            
            return "".join(content_parts)
        except Exception as e:
            logging.warning(f"PyPDF2 –æ—à–∏–±–∫–∞: {e}")
            # Fallback –Ω–∞ pdfplumber –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if PDF_PLUMBER_AVAILABLE:
                try:
                    content_parts = []
                    with pdfplumber.open(io.BytesIO(raw_bytes)) as pdf:
                        progress_bar = st.progress(0) if len(pdf.pages) > 2 else None
                        for i, page in enumerate(pdf.pages):
                            text = page.extract_text()
                            if text:
                                content_parts.append(text + "\n")
                            if progress_bar and i % max(1, len(pdf.pages) // 20) == 0:
                                progress_bar.progress((i + 1) / len(pdf.pages))
                        if progress_bar:
                            progress_bar.empty()
                    return "".join(content_parts)
                except Exception as e2:
                    logging.error(f"pdfplumber –æ—à–∏–±–∫–∞: {e2}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è PDF: {e}"

    def _extract_docx_content(self, raw_bytes) -> str:
        doc = docx.Document(io.BytesIO(raw_bytes))
        content_parts = [para.text + "\n" for para in doc.paragraphs]
        return "".join(content_parts)

    def _extract_csv_content(self, raw_bytes) -> str:
        decoded = io.StringIO(raw_bytes.decode("utf-8", errors="ignore"))
        reader = csv.reader(decoded)
        return "\n".join([", ".join(row) for row in reader])

    def _extract_pptx_content(self, file_path: str) -> str:
        prs = Presentation(file_path)
        content_parts = []

        for slide_num, slide in enumerate(prs.slides, 1):
            content_parts.append(f"Slide {slide_num}:\n")
            for shape in slide.shapes:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ text_frame, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if getattr(shape, "has_text_frame", False):
                    text_frame = getattr(shape, "text_frame", None)
                    if text_frame:
                        for paragraph in getattr(text_frame, "paragraphs", []):
                            text = getattr(paragraph, "text", "").strip()
                            if text:
                                content_parts.append(text + "\n")
                else:
                    text = getattr(shape, "text", "").strip()
                    if text:
                        content_parts.append(text + "\n")

        return "\n".join(content_parts)


    def _extract_xlsx_content(self, raw_bytes) -> str:
        if not XLSX_AVAILABLE:
            return "‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ openpyxl –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
            
        try:
            workbook = openpyxl.load_workbook(io.BytesIO(raw_bytes), read_only=True)
            content_parts = []
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                content_parts.append(f"Sheet: {sheet_name}\n")
                for row in sheet.iter_rows(values_only=True):
                    content_parts.append(", ".join(str(cell) if cell is not None else "" for cell in row) + "\n")
            return "".join(content_parts)
        except Exception as e:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è XLSX: {e}"

    async def _save_chunks_as_messages_async(self, chunks: list, timestamp: str, 
                                           qdrant_manager: QdrantManager, encoder_manager, 
                                           role: str = "file", progress_bar=None):
        try:
            if not chunks:
                return
                
            vectors = await encoder_manager.async_encode(chunks, batch_size=min(32, len(chunks)))
            
            points = []
            for chunk, vec in zip(chunks, vectors):
                vector_list = vec if isinstance(vec, list) else list(vec)
                point = qmodels.PointStruct(
                    id=str(uuid.uuid4()),
                    vector=vector_list,
                    payload={"role": role, "content": chunk, "time": timestamp}
                )
                points.append(point)
            
            batch_size = 64
            total_points = len(points)
            
            for i in range(0, total_points, batch_size):
                batch = points[i:i + batch_size]
                qdrant_manager.client.upsert(
                    collection_name=qdrant_manager.collection_name, 
                    points=batch
                )
                
                if progress_bar and total_points > batch_size:
                    progress_bar.progress(min(1.0, (i + batch_size) / total_points))
            
            logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(points)} —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤: {e}")
            raise

    def _save_chunks_as_messages(self, chunks: list, timestamp: str, 
                               qdrant_manager: QdrantManager, encoder_manager, role: str = "file"):
        try:
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            progress = st.progress(0) if len(chunks) > 32 else None
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º asyncio.wait_for –¥–ª—è —Ç–∞–π–º–∞—É—Ç–∞
            try:
                future = asyncio.wait_for(
                    self._save_chunks_as_messages_async(chunks, timestamp, qdrant_manager, encoder_manager, role, progress),
                    timeout=Config.STREAM_TIMEOUT
                )
                loop.run_until_complete(future)
            except asyncio.TimeoutError:
                st.sidebar.warning("‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —á–∞–Ω–∫–æ–≤")
                logging.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —á–∞–Ω–∫–æ–≤")
            
            if progress:
                progress.empty()
                
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤: {e}")
            st.sidebar.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤: {e}")

class Validator:
    def validate_prompt(self, prompt: str) -> bool:
        if not prompt or not prompt.strip():
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–µ–ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            logging.warning("–ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
            return False
        
        if len(prompt) > Config.MAX_MESSAGE_LENGTH:
            st.error(f"–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å–∏–º—É–º {Config.MAX_MESSAGE_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)")
            return False

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        dangerous_patterns = [
            "<?php", "<script", "javascript:", "onload=", 
            "base64_decode", "eval(", "system(", "exec(",
            "union select", "drop table", "insert into",
            "delete from", "update.*set", "create table"
        ]
        
        # HTML escape –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        prompt_sanitized = html.escape(prompt.lower())
        
        if any(pattern in prompt_sanitized for pattern in dangerous_patterns):
            st.error("–°–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
            logging.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏: {prompt[:100]}...")
            return False
            
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏
        sql_keywords = ['select', 'insert', 'update', 'delete', 'drop', 'create', 'alter']
        if any(keyword in prompt_sanitized for keyword in sql_keywords):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            suspicious_combos = ['\'', '"', '--', '/*', '*/', ';']
            if any(combo in prompt for combo in suspicious_combos):
                st.error("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–æ–∑–º–æ–∂–Ω–∞—è SQL-–∏–Ω—ä–µ–∫—Ü–∏—è")
                logging.warning(f"–í–æ–∑–º–æ–∂–Ω–∞—è SQL-–∏–Ω—ä–µ–∫—Ü–∏—è: {prompt[:100]}...")
                return False
            
        return True

    def validate_url(self, url: str) -> bool:
        if not url:
            return False
            
        try:
            if not url.startswith(('http://', 'https://')):
                return False
                
            result = urlparse(url)
            if not all([result.scheme, result.netloc]):
                return False
                
            return True
        except Exception:
            return False

    def validate_file_extension(self, filename: str) -> bool:
        allowed_extensions = {"txt", "pdf", "docx", "csv"}
        if PPTX_AVAILABLE:
            allowed_extensions.add("pptx")
        if XLSX_AVAILABLE:
            allowed_extensions.add("xlsx")
        file_ext = filename.lower().split('.')[-1] if '.' in filename else ""
        return file_ext in allowed_extensions

# ==================== GLOBAL INSTANCES ====================
config = Config()
qdrant_manager = QdrantManager(config.QDRANT_HOST, config.QDRANT_PORT, config.COLLECTION_NAME)
encoder_manager = EncoderManager()
ollama_client = OllamaClient()
file_processor = FileProcessor()
validator = Validator()
message_manager = MessageManager()

# ==================== SESSION STATE INITIALIZATION ====================
if "encoder" not in st.session_state:
    st.session_state.encoder = encoder_manager.load_encoder(config.DEFAULT_EMBEDDING_MODEL)
    qdrant_manager.init_collection(st.session_state.encoder)

if "messages" not in st.session_state:
    try:
        st.session_state.messages = message_manager.load_messages(qdrant_manager)
    except Exception as e:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        st.session_state.messages = []

if "ollama_status" not in st.session_state:
    st.session_state.ollama_status, st.session_state.ollama_message = ollama_client.check_api(config.OLLAMA_URL)

if "context_cache" not in st.session_state:
    st.session_state.context_cache = OrderedDict()
    st.session_state.context_cache_max_size = config.MAX_CACHE_SIZE

if "stats" not in st.session_state:
    st.session_state.stats = {
        "messages_sent": 0,
        "files_processed": 0,
        "chunks_saved": 0
    }

# ==================== ASYNC THREAD HELPER ====================
def async_stream_thread(q: Queue, *args):
    async def inner_gen():
        try:
            async for token in ollama_client.ask_llm_async_stream(*args):
                q.put(token)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ inner_gen: {e}")
            q.put(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∞: {e}")
        finally:
            q.put(None)

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(inner_gen())
    finally:
        loop.close()

# ==================== UI COMPONENTS ====================
def render_sidebar():
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        base_url = st.text_input("Ollama URL", config.OLLAMA_URL)
        model = st.text_input("–ú–æ–¥–µ–ª—å", config.DEFAULT_LLM_MODEL)
        max_context = st.slider("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞", 2, 20, 6)
        embedder = st.selectbox("–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤", ["all-MiniLM-L6-v2", "all-mpnet-base-v2"])
        max_tokens = st.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞", 50, 1000, 200)
        temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 0.0, 1.5, 0.3)
        top_p = st.slider("Top-p", 0.1, 1.0, 0.8)
        top_k = st.slider("Top-k", 1, 100, 40)

        if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —ç–Ω–∫–æ–¥–µ—Ä"):
            st.session_state.encoder = encoder_manager.load_encoder(embedder)
            qdrant_manager.init_collection(st.session_state.encoder)
            st.success(f"–≠–Ω–∫–æ–¥–µ—Ä {embedder} –∑–∞–≥—Ä—É–∂–µ–Ω")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        supported_formats = ["txt", "pdf", "docx", "csv"]
        if PPTX_AVAILABLE:
            supported_formats.append("pptx")
        if XLSX_AVAILABLE:
            supported_formats.append("xlsx")
            
        uploaded_files = st.file_uploader(
            "üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã", 
            type=supported_formats, 
            accept_multiple_files=True
        )
        
        st.markdown("---")
        if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç —á–∞—Ç–∞"):
            if st.session_state.messages:
                chat_data = {
                    "exported_at": datetime.now().isoformat(),
                    "messages": st.session_state.messages,
                    "stats": st.session_state.stats
                }
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é",
                    data=json.dumps(chat_data, ensure_ascii=False, indent=2),
                    file_name=f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            else:
                st.info("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")

        uploaded_chat = st.file_uploader("üì§ –ò–º–ø–æ—Ä—Ç —á–∞—Ç–∞", type=["json"])
        if uploaded_chat:
            try:
                chat_data = json.load(uploaded_chat)
                st.session_state.messages = chat_data.get("messages", [])
                if "stats" in chat_data:
                    st.session_state.stats = chat_data["stats"]
                st.success("–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞")
                st.rerun()
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        
        if st.button("üóë –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"):
            st.session_state.messages = []
            try:
                qdrant_manager.clear_collection(st.session_state.encoder)
                st.session_state.context_cache.clear()
                encoder_manager.cache.clear()
                st.session_state.stats = {
                    "messages_sent": 0,
                    "files_processed": 0,
                    "chunks_saved": 0
                }
                st.success("–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞")
                logging.info("–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Qdrant: {e}")
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Qdrant: {e}")
            st.rerun()

        st.markdown("---")
        if st.button("üìÇ –ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"):
            try:
                file_messages = []
                all_messages = qdrant_manager.load_messages(limit=100)
                for msg in all_messages:
                    if msg.get('role') == 'file':
                        file_messages.append(msg)
                
                if file_messages:
                    st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(set(msg.get('time', '') for msg in file_messages))}")
                    files_by_time = {}
                    for msg in file_messages:
                        time_key = msg.get('time', 'unknown')
                        if time_key not in files_by_time:
                            files_by_time[time_key] = []
                        files_by_time[time_key].append(msg)
                    
                    for time_key, chunks in files_by_time.items():
                        with st.expander(f"–§–∞–π–ª –æ—Ç {time_key} ({len(chunks)} —á–∞–Ω–∫–æ–≤)"):
                            if chunks:
                                st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:", chunks[0].get('content', '')[:500] + "...", height=100, key=f"file_{time_key}")
                else:
                    st.info("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {e}")

        st.markdown("---")
        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        st.write(f"–°–æ–æ–±—â–µ–Ω–∏–π: {st.session_state.stats.get('messages_sent', 0)}")
        st.write(f"–§–∞–π–ª–æ–≤: {st.session_state.stats.get('files_processed', 0)}")
        st.write(f"–ß–∞–Ω–∫–æ–≤: {st.session_state.stats.get('chunks_saved', 0)}")
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
        cache_stats = encoder_manager.cache.get_stats()
        st.write(f"–ö—ç—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {cache_stats['size']}/{cache_stats['max_size']} ({cache_stats['usage_percent']:.1f}%)")

    return base_url, model, max_context, max_tokens, temperature, top_p, top_k, uploaded_files

# ==================== MAIN ====================
def main():
    st.set_page_config(page_title="LLM Chat", layout="wide")
    st.title("üí¨ LLM –ß–∞—Ç")

    if config.DEBUG_MODE:
        st.sidebar.info("DEBUG —Ä–µ–∂–∏–º –≤–∫–ª—é—á–µ–Ω")

    base_url, model, max_context, max_tokens, temperature, top_p, top_k, uploaded_files = render_sidebar()

    if st.session_state.ollama_status:
        st.success(f"üü¢ {st.session_state.ollama_message}")
    else:
        st.error(f"üî¥ {st.session_state.ollama_message}")

    if uploaded_files:
        for file in uploaded_files:
            result = file_processor.process_file(file, qdrant_manager, encoder_manager, config.MAX_FILE_SIZE_MB)
            st.sidebar.success(result)

    for msg in st.session_state.messages:
        with st.chat_message(msg.get("role", "user")):
            st.write(msg.get("content", ""))
            st.caption(f"_{msg.get('time', '')}_")

    if st.session_state.ollama_status and (prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")):
        if not validator.validate_prompt(prompt):
            st.rerun()
        
        ts = datetime.now().strftime("%H:%M:%S")
        qdrant_manager.save_message("user", prompt, ts, encoder_manager)
        st.session_state.messages.append({"role": "user", "content": prompt, "time": ts})
        
        st.session_state.stats["messages_sent"] = st.session_state.stats.get("messages_sent", 0) + 1
        
        with st.chat_message("user"):
            st.write(prompt)
            st.caption(f"_{ts}_")

        with st.chat_message("assistant"):
            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            progress_placeholder = st.empty()
            progress_placeholder.info("‚è≥ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞...")
            
            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
                context = qdrant_manager.search_context(prompt, encoder_manager, max_context)
                progress_placeholder.empty()  # –£–±–∏—Ä–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
                
                if config.DEBUG_MODE:
                    with st.expander("üîç –†–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–ª–∞–¥–∫–∞)", expanded=False):
                        st.write(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(context)}")
                        chat_count = sum(1 for msg in context if msg.get('role') in ['user', 'assistant'])
                        file_count = sum(1 for msg in context if msg.get('role') == 'file')
                        st.write(f"–ß–∞—Ç: {chat_count}, –§–∞–π–ª—ã: {file_count}")
                        
                        for i, msg in enumerate(context):
                            role = msg.get('role', 'unknown')
                            role_emoji = "üë§" if role == "user" else "ü§ñ" if role == "assistant" else "üìÑ" if role == "file" else "‚ùì"
                            st.write(f"**{i+1}. {role_emoji} {role.capitalize()}** ({msg.get('time', 'N/A')}):")
                            content = msg.get('content', '')
                            st.code(content[:300] + ('...' if len(content) > 300 else ''))
                
                stop_button = st.empty()
                stop_generation = False
                
                q = Queue()
                thread = threading.Thread(
                    target=async_stream_thread,
                    args=(q, prompt, context, model, base_url, max_tokens, temperature, top_p, top_k),
                    daemon=True
                )
                thread.start()

                full_response = ''
                placeholder = st.empty()
                
                stop_key = f"stop_{ts.replace(':', '_')}"
                if stop_button.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é", key=stop_key):
                    stop_generation = True
                    stop_button.empty()
                
                # –¢–∞–π–º–µ—Ä –¥–ª—è —Ç–∞–π–º–∞—É—Ç–∞
                start_time = datetime.now()
                
                while not stop_generation:
                    try:
                        chunk = q.get(timeout=0.5)  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
                        if chunk is None:
                            break
                        full_response += chunk
                        placeholder.markdown(full_response)
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞
                        if (datetime.now() - start_time).seconds > Config.STREAM_TIMEOUT:
                            stop_generation = True
                            full_response += "\n\n‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"
                            break
                            
                    except:
                        # –¢–∞–π–º–∞—É—Ç - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                        if stop_generation or (datetime.now() - start_time).seconds > Config.STREAM_TIMEOUT:
                            break
                        continue
                
                # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞
                try:
                    thread.join(timeout=5)  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
                except:
                    pass
                stop_button.empty()

        ts_reply = datetime.now().strftime("%H:%M:%S")
        if stop_generation and not full_response.strip():
            final_response = "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."
        elif not full_response.strip():
            final_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."
        else:
            final_response = full_response.strip()

        qdrant_manager.save_message("assistant", final_response, ts_reply, encoder_manager)
        st.session_state.messages.append({"role": "assistant", "content": final_response, "time": ts_reply})
        st.rerun()

if __name__ == "__main__":
    main()